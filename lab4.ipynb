{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lab4.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":86},"id":"k-gMHm7DtPX5","executionInfo":{"status":"ok","timestamp":1655199974822,"user_tz":-180,"elapsed":47577,"user":{"displayName":"SkylarGrey_Pro TopPlayer","userId":"06783244784785003234"}},"outputId":"6082d01c-e3d4-46a5-e638-f3f43afd2e6b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-c3f0ef65-40ec-46dc-a2b9-3ed093cb5bb2\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-c3f0ef65-40ec-46dc-a2b9-3ed093cb5bb2\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle.json to kaggle.json\n"]},{"output_type":"execute_result","data":{"text/plain":["{'kaggle.json': b'{\"username\":\"skylarpro\",\"key\":\"61c6a5a697295af30a778f1880685730\"}'}"]},"metadata":{},"execution_count":1}],"source":["from google.colab import files\n","files.upload()\n"]},{"cell_type":"code","source":["!rm -r ~/.kaggle\n","!mkdir ~/.kaggle\n","!mv ./kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","!kaggle datasets list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3HxY6EUtg8v","executionInfo":{"status":"ok","timestamp":1655199979104,"user_tz":-180,"elapsed":1119,"user":{"displayName":"SkylarGrey_Pro TopPlayer","userId":"06783244784785003234"}},"outputId":"2226abdd-9a6a-4f74-a6f3-01fdd2f14234"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["rm: cannot remove '/root/.kaggle': No such file or directory\n","ref                                                          title                                                size  lastUpdated          downloadCount  voteCount  usabilityRating  \n","-----------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n","victorsoeiro/netflix-tv-shows-and-movies                     Netflix TV Shows and Movies                           2MB  2022-05-15 00:01:23           7624        236  1.0              \n","devansodariya/student-performance-data                       Student Performance Dataset                           7KB  2022-05-26 13:55:09           3329        131  0.9705882        \n","iamsouravbanerjee/software-professional-salaries-2022        Salary Dataset - 2022                               526KB  2022-06-10 06:02:59           1236         37  1.0              \n","paradisejoy/top-hits-spotify-from-20002019                   Top Hits Spotify from 2000-2019                      94KB  2022-05-31 07:20:57           5990        147  1.0              \n","surajjha101/stores-area-and-sales-data                       Supermarket store branches sales analysis            10KB  2022-04-29 11:10:16           6196        178  1.0              \n","mayureshkoli/police-deaths-in-usa-from-1791-to-2022          Police deaths in USA from 1791 to 2022              698KB  2022-06-09 17:47:57            463         24  1.0              \n","saddamazyazy/go-to-college-dataset                           Go To College Dataset                                12KB  2022-05-20 10:46:02           1275         33  1.0              \n","gunapro/student-behavior                                     Student Behavior                                      5KB  2022-06-03 13:45:54            966         37  0.7647059        \n","odins0n/amex-parquet                                         Amex Competition Data in Parquet Format               9GB  2022-05-25 23:20:19            779        104  1.0              \n","ahmedshahriarsakib/usa-real-estate-dataset                   USA Real Estate Dataset                               5MB  2022-06-04 21:40:25            773         31  1.0              \n","kkhandekar/cost-of-living-index-by-city-2022                 Cost of Living Index by City 2022                    15KB  2022-06-03 02:50:24            753         26  1.0              \n","ruchi798/parquet-files-amexdefault-prediction                Feather & Parquet Files : AMEX-Default Prediction    22GB  2022-05-26 05:46:53            571         87  1.0              \n","azminetoushikwasi/ucl-202122-uefa-champions-league           UCL ⚽ 2021-22 ⭐ Players Data | Champions League      55KB  2022-06-13 08:36:43           1165         44  1.0              \n","prasertk/cities-with-the-best-worklife-balance-2022          Cities with the Best Work-Life Balance 2022           5KB  2022-06-01 09:15:52            671         27  1.0              \n","kuchhbhi/play-store-apps-may2022                             Play Store Apps May-2022                            468KB  2022-05-19 07:57:19            720         26  1.0              \n","aryashah2k/sample-students-grades-dataset-tutorial-notebook  Sample Students Grades Dataset Tutorial Notebook     360B  2022-06-07 09:11:25            196         25  1.0              \n","dansbecker/melbourne-housing-snapshot                        Melbourne Housing Snapshot                          451KB  2018-06-05 12:52:24          88747       1084  0.7058824        \n","imoore/age-dataset                                           Age dataset: life, work, and death of 1.22M people   34MB  2022-06-07 08:56:52            357         34  1.0              \n","ankanhore545/dropout-or-academic-success                     Predict Dropout or Academic Success                 103KB  2022-06-05 11:32:43            411         24  0.9117647        \n","datasnaek/youtube-new                                        Trending YouTube Video Statistics                   201MB  2019-06-03 00:56:47         176862       4556  0.7941176        \n"]}]},{"cell_type":"code","source":["https://www.kaggle.com/datasets/arkhoshghalb/twitter-sentiment-analysis-hatred-speech\n","\n","!kaggle datasets download \"gpreda/covid19-tweets\"\n","!unzip /content/covid19-tweets.zip"],"metadata":{"id":"Db-04mqIm2ek"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!kaggle datasets download \"arkhoshghalb/twitter-sentiment-analysis-hatred-speech\"\n","# !unzip /content/arkhoshghalb/twitter-sentiment-analysis-hatred-speech.zip\n","!unzip /content/twitter-sentiment-analysis-hatred-speech.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6aW26kPQthkZ","executionInfo":{"status":"ok","timestamp":1655200008433,"user_tz":-180,"elapsed":924,"user":{"displayName":"SkylarGrey_Pro TopPlayer","userId":"06783244784785003234"}},"outputId":"21d1db54-f640-4495-a45d-a16d11768edb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading twitter-sentiment-analysis-hatred-speech.zip to /content\n","\r  0% 0.00/1.89M [00:00<?, ?B/s]\n","\r100% 1.89M/1.89M [00:00<00:00, 199MB/s]\n"]}]},{"cell_type":"markdown","source":["##Подготовьте набор данных для дальнейшей работы"],"metadata":{"id":"yfsnA9ootZQM"}},{"cell_type":"markdown","source":["Для данной задачи подготовка заключается в удалении лишних символов и знаков препинания, а также приведении к нижнему регистру и токенизации"],"metadata":{"id":"Vn-81DE5truD"}},{"cell_type":"code","source":["import re\n","import pandas as pd\n","import string\n","import numpy as np"],"metadata":{"id":"2SNdFcrot_sw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def _processing_text(proc_text):\n","        proc_text = proc_text.lower()\n","        proc_text = proc_text.replace(\"\\n\",\" \")\n","        proc_text = re.sub(r\"http\\S+\", \"\",proc_text)\n","        proc_text = re.sub(\"#(\\w+)\", \" \", proc_text)\n","        proc_text = re.sub(\"@(\\w+)\", \" \", proc_text)\n","        \n","        proc_text = re.sub('[^a-z]', \" \", proc_text)\n","        proc_text = re.sub(\" +\", \" \", proc_text)\n","        \n","      \n","        proc_text = [char for char in proc_text if char not in string.punctuation]\n","        proc_text = ''.join(proc_text)\n","        return proc_text"],"metadata":{"id":"NkePjl9ruONS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_2[\"text\"].iloc[2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":166},"id":"0bsMPC49Ql-A","executionInfo":{"status":"error","timestamp":1654725074748,"user_tz":-180,"elapsed":9,"user":{"displayName":"Viktor Kumpan","userId":"13855502838544770278"}},"outputId":"240199c6-b18e-4f43-8121-22d858ee6b7f"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-28077ed43e1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'df_2' is not defined"]}]},{"cell_type":"code","source":["df_2[\"text_proc\"].iloc[2]"],"metadata":{"id":"WpRj6N3KReJp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_2 = pd.read_csv(\"/content/covid19_tweets.csv\")\n","df_2[\"text_proc\"] = df_2[\"text\"].apply(_processing_text)\n","df_2[\"text_proc\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZXzqT7b_taMn","executionInfo":{"status":"ok","timestamp":1654725088931,"user_tz":-180,"elapsed":13889,"user":{"displayName":"Viktor Kumpan","userId":"13855502838544770278"}},"outputId":"4d4b8e09-f92c-4420-97e0-fd802127ba7d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0         if i smelled the scent of hand sanitizers toda...\n","1         hey and wouldn t it have made more sense to ha...\n","2          trump never once claimed was a hoax we all cl...\n","3          the one gift has give me is an appreciation f...\n","4                             july media bulletin on novel \n","                                ...                        \n","179103    thanks for nominating me for the challenge i n...\n","179104                            the year of insanity lol \n","179105     a powerful painting by juan lucena it s a tri...\n","179106    more than students test positive for at major ...\n","179107                            i stop when i see a stop \n","Name: text_proc, Length: 179108, dtype: object"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["##Выделите уникальные слова, создайте словарь, в котором ключами будут являться слова, а значениями соответствующие им индексы"],"metadata":{"id":"C0dsvLGguZUJ"}},{"cell_type":"markdown","source":["Используйте метод fit_on_texts  модуля keras.preprocessing.text. Должен получиться один словарь, содержащий слова со всех строк набора данных. В реализации этого и дальнейших пунктов могут помочь полезные материалы."],"metadata":{"id":"Zdjv6wndubaw"}},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vgJpTG0Wwhlr","executionInfo":{"status":"ok","timestamp":1654725093052,"user_tz":-180,"elapsed":4127,"user":{"displayName":"Viktor Kumpan","userId":"13855502838544770278"}},"outputId":"570ebccd-34fc-496f-a420-065d5ad40244"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"]}]},{"cell_type":"code","source":["training_corpus = df_2[\"text_proc\"].to_numpy()"],"metadata":{"id":"ZAA81C1HyLQ1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","old_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"],"metadata":{"id":"Mu3sENX7uaq1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["old_res = old_tokenizer.tokenize(training_corpus[0])"],"metadata":{"id":"ETiwZPE0yI6M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, 30000)"],"metadata":{"id":"S0x80FX3wsLd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_res = tokenizer.tokenize(training_corpus[0])"],"metadata":{"id":"rgEW30CJysDj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["assert not np.all(old_res == new_res)"],"metadata":{"id":"JU65ZmLhyft3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Создайте модель нейронной сети"],"metadata":{"id":"BXyAPvFlzJce"}},{"cell_type":"markdown","source":["Из библиотеки keras  импортируйте тип модели Sequential, добавьте в неё 3 слоя LSTM и слой Dense. Так как мы имеем дело с многоклассовой классификацией (количество классов соответствует количеству слов в наборе данных), в качестве функции потери используется categorical_crossentropy. Вы можете попробовать улучить модель путём подбора гиперпараметров."],"metadata":{"id":"MYcbN2YkzNyC"}},{"cell_type":"markdown","source":["1. Сделать LSTM\n","2. Добавить Conv в cделанную LSTM\n","3. Добавить Attention в LSTM на шаге два\n","4. Добавить Bidirectional\n"],"metadata":{"id":"XPav6FMU0Li4"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch\n","import torch.nn.functional as F\n","from collections import OrderedDict\n","import math"],"metadata":{"id":"ifTT2fWfzUBT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class LSTMLayerEncoder(nn.Module):\n","  def __init__(self,input_size, hidden_size):\n","    super().__init__()\n","    self.hidden_size = hidden_size\n","\n","    self.W = nn.Parameter(torch.Tensor(input_size, hidden_size * 4))\n","    self.V = nn.Parameter(torch.Tensor(hidden_size,hidden_size * 4))\n","    self.bias = nn.Parameter(torch.Tensor(hidden_size * 4))\n","    self.init_weights()\n","    self.dorpout = nn.Dropout(p=0.1)\n","\n","  def init_weights(self):\n","        stdv = 1.0 / math.sqrt(self.hidden_size)\n","        for weight in self.parameters():\n","            weight.data.uniform_(-stdv, stdv)\n","    \n","  def forward(self,input, init_states=None):\n","    bs, seq_len, _ = input.shape\n","\n","    if init_states is None:\n","      h_t = torch.zeros((bs, self.hidden_size)).cuda()\n","      c_t = torch.zeros((bs, self.hidden_size)).cuda()\n","    else:\n","      h_t, c_t = init_states\n","\n","    HS = self.hidden_size\n","    hidden_seq = []\n","\n","    for t in range(seq_len):\n","      x_t = input[:,t,:]\n","      gates = x_t@self.W + h_t@self.V + self.bias\n","\n","      # (b_s,inp_size)@ (inp_size, hid*4) = (b_s, hid*4) \n","      # (b_s, hid) @ (hid,hid*4) = (b_s, hid*4) \n","      # (b_s, hid*4) + (hid*4) = (b_s, hid*4)\n","      i_t, f_t, g_t, o_t = (\n","                F.sigmoid(gates[:, :HS]), # input\n","                F.sigmoid(gates[:, HS:HS*2]), # forget\n","                F.tanh(gates[:, HS*2:HS*3]),\n","                F.sigmoid(gates[:, HS*3:]), # output\n","      )\n","      \n","      c_t = c_t*f_t + i_t*g_t\n","      h_t = o_t * F.tanh(c_t)\n","\n","      h_t = self.dorpout(h_t)\n","\n","      hidden_seq.append(h_t.unsqueeze(0))\n","\n","    hidden_seq = torch.cat(hidden_seq, dim=0) \n","    hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n","    return hidden_seq, (h_t, c_t)\n","\n","class LSTMLayerDecoder(nn.Module):\n","  def __init__(self,input_size, hidden_size, max_len_generation, vocab_size, embeding_model):\n","    super().__init__()\n","    self.hidden_size = hidden_size\n","    self.max_len_generation = max_len_generation\n","\n","    self.W = nn.Parameter(torch.Tensor(input_size, hidden_size * 4))\n","    self.V = nn.Parameter(torch.Tensor(hidden_size,hidden_size * 4))\n","    self.bias = nn.Parameter(torch.Tensor(hidden_size * 4))\n","    self.init_weights()\n","\n","    self.embeding_model = embeding_model\n","    self.dorpout = nn.Dropout()\n","\n","    self.projection = nn.Sequential(\n","        nn.Linear(hidden_size, vocab_size),\n","        nn.Sigmoid()\n","        )\n","\n","  def init_weights(self):\n","        stdv = 1.0 / math.sqrt(self.hidden_size)\n","        for weight in self.parameters():\n","            weight.data.uniform_(-stdv, stdv)\n","    \n","  def forward(self,input, init_states):\n","\n","    h_t, c_t = init_states\n","\n","    HS = self.hidden_size\n","    predict_words = []\n","    hash_prediction = []\n","\n","\n","    x_t = input[:,0,:]\n","    for _ in range(self.max_len_generation):\n","      gates = x_t@self.W + h_t@self.V + self.bias\n","\n","      i_t, f_t, g_t, o_t = (\n","                F.sigmoid(gates[:, :HS]), # input\n","                F.sigmoid(gates[:, HS:HS*2]), # forget\n","                F.tanh(gates[:, HS*2:HS*3]),\n","                F.sigmoid(gates[:, HS*3:]), # output\n","      )\n","      \n","      c_t = c_t*f_t + i_t*g_t\n","      h_t = o_t * F.tanh(c_t)\n","\n","      predict_word = self.projection(h_t)\n","      next_pred = torch.argmax(predict_word, dim = 1).unsqueeze(1)\n","      x_t = self.embeding_model(next_pred)[:,0,:]\n","\n","      hash_prediction.append(predict_word.unsqueeze(1)) #(b_s, vocab_size,1)\n","\n","      predict_words.append(next_pred) # (b_s, 1)\n","\n","    predict_words = torch.cat(predict_words, dim=1) \n","\n","    hash_prediction = torch.cat(hash_prediction, dim=1)  #(b_s, vocab_size, len_generation)\n","\n","    return hash_prediction, predict_words\n","\n","class CustomLSTM(nn.Module):\n","  def __init__(self, input_size, hidden_size, num_layers,\n","               max_len_generation, vocab_size, embeding_model):\n","    super().__init__()\n","    self.LSTM_encoder1 = LSTMLayerEncoder(input_size, hidden_size) #nn.Sequential(OrderedDict({f\"lstm_layer{i+1}\":\n","     #for i in range(num_layers)}))\n","    self.LSTM_encoder2 = LSTMLayerEncoder(hidden_size, hidden_size)\n","    self.dorpout = nn.Dropout(p=0.15)\n","    self.LSTM_encoder3 = LSTMLayerEncoder(hidden_size, hidden_size)\n","\n","    self.LSTM_decoder = LSTMLayerDecoder(input_size, hidden_size, max_len_generation,\n","                                         vocab_size,embeding_model) #nn.Sequential(OrderedDict({f\"lstm_layer{i+1}\":\n","     #for i in range(num_layers)}))\n","\n","  def forward(self, input_encoder, input_decoder, init_states = None):\n","    hidden_seq, _ = self.LSTM_encoder1(input_encoder)\n","    hidden_seq = self.dorpout(hidden_seq)\n","    hidden_seq, _ = self.LSTM_encoder2(hidden_seq)\n","    hidden_seq = self.dorpout(hidden_seq)\n","    _, (h_t, c_t) = self.LSTM_encoder3(hidden_seq)\n","    out = self.LSTM_decoder(input_decoder, (h_t, c_t))\n","    return out"],"metadata":{"id":"UDeY5oOMzKoo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataloader \n"],"metadata":{"id":"3QwS-ji3NxTD"}},{"cell_type":"code","source":["from transformers import BertTokenizer\n","from transformers import BertModel\n","\n","BERT_MODEL = \"distilbert-base-uncased\"\n","tokenizer = BertTokenizer.from_pretrained(BERT_MODEL) \n","model_bert = BertModel.from_pretrained(BERT_MODEL)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"erYWftCbSCyk","executionInfo":{"status":"ok","timestamp":1654726076842,"user_tz":-180,"elapsed":2470,"user":{"displayName":"Viktor Kumpan","userId":"13855502838544770278"}},"outputId":"cfc42e54-0582-4377-af3e-0d94a140982b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n","The class this function is called from is 'BertTokenizer'.\n","You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing BertModel: ['distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'vocab_transform.bias', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'vocab_projector.bias', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'vocab_projector.weight', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'vocab_layer_norm.weight', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'vocab_layer_norm.bias', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'vocab_transform.weight', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.0.ffn.lin2.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertModel were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.weight', 'pooler.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.8.attention.self.key.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.0.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader,SubsetRandomSampler\n","import torch\n","\n","class TweetDataset(Dataset):\n","\n","  def __init__(self,data, tokenizer, max_seq_length):\n","    self.text_data = data\n","    self.tokenizer = tokenizer\n","    self.max_seq_length = max_seq_length\n","\n","  def __getitem__(self,idx):\n","        text = self.text_data[idx]\n","        input_ids = self.tokenizer.encode(f\"{text}\")[1:]\n","        \n","\n","        if len(input_ids) > self.max_seq_length:\n","            input_ids = input_ids[:self.max_seq_length]\n","\n","        # Zero-pad up to the sequence length.\n","        padding = [0] * (self.max_seq_length - len(input_ids))\n","        input_ids += padding\n","\n","        attention_mask = [1] * len(input_ids)\n","\n","        # Zero-pad up to the sequence length.\n","        padding = [0] * (self.max_seq_length - len(input_ids))\n","        input_ids += padding\n","        attention_mask += padding\n","\n","        decoder_start = [101]\n","\n","        return torch.tensor(input_ids), torch.tensor(attention_mask), torch.tensor(decoder_start)\n","\n","  def __len__(self,):\n","    return self.text_data.shape[0]\n","\n","LEN_SEQ = 7\n","train_dataset = TweetDataset(training_corpus, tokenizer, max_seq_length = LEN_SEQ)"],"metadata":{"id":"FxXKg-2ENlCu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_corpus"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SIU_PtfYQa7D","executionInfo":{"status":"ok","timestamp":1654726640629,"user_tz":-180,"elapsed":4,"user":{"displayName":"Viktor Kumpan","userId":"13855502838544770278"}},"outputId":"ba1d4c9f-45f8-41ad-a2e1-3ca878cb3c9f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['if i smelled the scent of hand sanitizers today on someone in the past i would think they were so intoxicated that ',\n","       'hey and wouldn t it have made more sense to have the players pay their respects to the a ',\n","       ' trump never once claimed was a hoax we all claim that this effort to ',\n","       ...,\n","       ' a powerful painting by juan lucena it s a tribute to the grandparents who died of covid and the grandc ',\n","       'more than students test positive for at major university abc news ',\n","       'i stop when i see a stop '], dtype=object)"]},"metadata":{},"execution_count":233}]},{"cell_type":"code","source":["def sempler_eval(data_train, batch_size = 128,):\n","    \n","    data_size = len(data_train)\n","\n","    eval_indices = np.array(list(range(data_size)))\n","    np.random.shuffle(eval_indices)\n","\n","    eval_sampler = SubsetRandomSampler(eval_indices)\n","\n","    eval_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size,\n","                                              sampler=eval_sampler,)\n","\n","    return eval_loader\n","\n","train_loader = sempler_eval(train_dataset)"],"metadata":{"id":"hVyzJgWUP6h8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_size = tokenizer.vocab_size\n","embeding_model = model_bert.embeddings\n","embeding_model.cuda()\n","embeding_model.requires_grad = False\n","embeding_model.eval()\n","model = CustomLSTM(768, 2048, 1, LEN_SEQ, vocab_size, embeding_model)\n","model.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dXQUvUc7lZLg","executionInfo":{"status":"ok","timestamp":1654726655798,"user_tz":-180,"elapsed":8070,"user":{"displayName":"Viktor Kumpan","userId":"13855502838544770278"}},"outputId":"ce562f52-8125-4c0d-a0a4-a20ab453c9bf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CustomLSTM(\n","  (LSTM_encoder1): LSTMLayerEncoder(\n","    (dorpout): Dropout(p=0.1, inplace=False)\n","  )\n","  (LSTM_encoder2): LSTMLayerEncoder(\n","    (dorpout): Dropout(p=0.1, inplace=False)\n","  )\n","  (dorpout): Dropout(p=0.15, inplace=False)\n","  (LSTM_encoder3): LSTMLayerEncoder(\n","    (dorpout): Dropout(p=0.1, inplace=False)\n","  )\n","  (LSTM_decoder): LSTMLayerDecoder(\n","    (embeding_model): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (dorpout): Dropout(p=0.5, inplace=False)\n","    (projection): Sequential(\n","      (0): Linear(in_features=5096, out_features=30522, bias=True)\n","      (1): Sigmoid()\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":236}]},{"cell_type":"code","source":["from tqdm import tqdm \n","from torch.optim import Adam"],"metadata":{"id":"pavvH8HTQM_u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.train()\n","loss = nn.CrossEntropyLoss()\n","for name,param in model.named_parameters():\n","  if name.find(\"embeding_model\")!=-1:\n","    param.requires_grad = False\n","\n","optim = Adam([param for param in model.parameters() if param.requires_grad ],lr = 1e-02, weight_decay=1e-4)"],"metadata":{"id":"9DLKWGrkmOyy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 1\n","loss_array = []\n","Acc_array = []\n","for epoch in range(epochs):\n","  loss_values = 0\n","  for idx, (text_to_encoder, attentiom_mask, text_to_decoder) in tqdm(enumerate(train_loader)):\n","\n","    text_to_encoder_cuda = text_to_encoder.cuda()\n","    attentiom_mask_cuda = attentiom_mask.cuda()\n","    text_to_decoder_cuda = text_to_decoder.cuda()\n","\n","    input_to_LSTM_encoder = embeding_model(text_to_encoder_cuda)\n","    input_to_LSTM_decoder = embeding_model(text_to_decoder_cuda)\n","\n","\n","    pred_probably, _ =  model(input_to_LSTM_encoder, input_to_LSTM_decoder)\n","    del input_to_LSTM_encoder\n","    del input_to_LSTM_decoder\n","    del attentiom_mask_cuda\n","    del text_to_decoder_cuda\n","\n","    loss_value = loss(pred_probably.transpose(1,2), text_to_encoder_cuda)\n","    optim.zero_grad()\n","    loss_value.backward()\n","    optim.step()\n","    loss_values+=loss_value\n","\n","    if idx!=0:\n","      print(f\"loss {loss_values/idx} on {idx} iter\")\n","    \n","    del pred_probably\n","    del text_to_encoder_cuda\n","    \n","  loss_array.append(loss_values)\n","  print(f\"Epoch {epoch}\")\n","  print(f\"Loss {loss_values/idx+1}\")"],"metadata":{"id":"fKbSvHvPmMaa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generation_sentence(model_gen, tokenizer):\n","  model_gen.eval()\n","  c_t = 2022*torch.rand((5,2048)).cuda()\n","  h_t = 502*torch.rand((5,2048)).cuda()\n","  token_start = embeding_model(torch.tensor([101]).unsqueeze(0).cuda())\n","  _,result = model_gen.LSTM_decoder(token_start,(h_t, c_t))\n","  decode_text = []\n","  for sample in result:\n","      decode_text.append(tokenizer.decode(sample))\n","  del c_t\n","  del h_t\n","  del token_start\n","  return decode_text"],"metadata":{"id":"9van18vyv0U9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generation_sentence(model, tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FLaNW0QpFM7_","executionInfo":{"status":"ok","timestamp":1654726582724,"user_tz":-180,"elapsed":5,"user":{"displayName":"Viktor Kumpan","userId":"13855502838544770278"}},"outputId":"49686bfe-820a-485a-d1be-e7e96791a5a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1933: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"]},{"output_type":"execute_result","data":{"text/plain":["['ru b b b b',\n"," 'school b b b b',\n"," 'which b b b b',\n"," 'could b b b b',\n"," 'ru b b b b']"]},"metadata":{},"execution_count":227}]},{"cell_type":"code","source":["from typing import List\n","\n","def generation_sentence_from_title(model_gen, model_emb, text_input: List[str], tokenizer):\n","  prep_text = list(map(_processing_text,text_input))\n","  tokenize_text = list(map(tokenizer.encode, prep_text))\n","  model_gen.eval()\n","  model_emb.eval()\n","  def form_vectors(tokenize_text):\n","    res_input = []\n","    res_att_mask = []\n","\n","    for text in tokenize_text:\n","      text = text[1:]\n","      if len(text) > LEN_SEQ:\n","            text = text[:LEN_SEQ]\n","\n","      padding = [0] * (LEN_SEQ - len(text))\n","      text += padding\n","\n","      attention_mask = [1] * len(text)\n","\n","      padding = [0] * (LEN_SEQ - len(text))\n","      text += padding\n","      attention_mask += padding\n","\n","      res_input.append(text)\n","      res_att_mask.append(attention_mask)\n","    res_input = torch.tensor(res_input)\n","    res_att_mask = torch.tensor(res_att_mask)\n","    decoder_start = torch.tensor([101]*len(tokenize_text)).unsqueeze(1)\n","\n","    return res_input, res_att_mask, decoder_start\n","\n","  res_input, res_att_mask, decoder_start = form_vectors(tokenize_text)\n","\n","  input_to_LSTM_decoder = model_emb(decoder_start.cuda())\n","  input_to_LSTM_encoder = model_emb(res_input.cuda())\n","\n","  _, result =  model_gen(input_to_LSTM_encoder, input_to_LSTM_decoder)\n","  decode_text = []\n","  for sample in result:\n","      decode_text.append(tokenizer.decode(sample))\n","\n","  del input_to_LSTM_decoder\n","  del input_to_LSTM_encoder\n","  del result\n","  return decode_text"],"metadata":{"id":"wN_sx6Nv_960"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generation_sentence_from_title(model,embeding_model,[\"covid19 india china asd sad\"],tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kLQRfDK_9Mff","executionInfo":{"status":"ok","timestamp":1654726598752,"user_tz":-180,"elapsed":249,"user":{"displayName":"Viktor Kumpan","userId":"13855502838544770278"}},"outputId":"25366094-fb3f-4053-fca6-ce0223a8dcff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1933: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"]},{"output_type":"execute_result","data":{"text/plain":["['b b b b b']"]},"metadata":{},"execution_count":230}]},{"cell_type":"markdown","source":["Проблема переобучения на b b b b возможна в виду плохих данных непригодных для генерации.\n","Из примера выше видно что если мы подадим сильный шум то сетка что-то предскажет не с b b но после она все равно скатется к этим значениям. Значит она переобучилась("],"metadata":{"id":"p7byXfoVQ86T"}}]}